---
title: "04-ensembling"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(tidymodels)

source(here::here("materials/exercises/04-helpers.R"))

get_tree_fit <- function(results) {
  results %>% 
    pluck(".workflow", 1) %>% 
    pull_workflow_fit() 
}

# read in the data
stackoverflow <- read_rds(here::here("materials/data/stackoverflow.rds")) %>% 
  select(-country)

# split the data
set.seed(100) # Important!
so_split <- initial_split(stackoverflow, strata = remote)
so_train <- training(so_split)
so_test  <- testing(so_split)
so_folds <- vfold_cv(so_train, strata = remote)
```

# Your turn 1

Fill in the blanks to return the accuracy and ROC AUC for the vanilla decision tree model.

```{r}
vanilla_tree_spec <-
  decision_tree() %>% 
  set_engine("rpart") %>% 
  set_mode("classification")

set.seed(100) # Important!
_________ %>% 
  _________(remote ~ ., 
            resamples = so_folds) %>% 
  _________
```

```{r}
vanilla_tree_spec <-
  decision_tree() %>% 
  set_engine("rpart") %>% 
  set_mode("classification")

set.seed(100) # Important!
vanilla_tree_spec %>% 
  fit_resamples(remote ~ ., 
                resamples = so_folds) %>% 
  collect_metrics()
```


# Your Turn 2

Create a new classification tree model spec; call it `big_tree_spec`. 
Set the cost complexity to `0`, and the minimum number of data points in a node to split to be `1`. 

Compare the metrics of the big tree to the vanilla tree- which one predicts the test set better?

*Hint: you'll need https://tidymodels.github.io/parsnip/reference/decision_tree.html*

```{r}

```

```{r}
big_tree_spec <-
  decision_tree(min_n = 1, cost_complexity = 0) %>% 
  set_engine("rpart") %>% 
  set_mode("classification")

set.seed(100)
big_tree_spec %>% 
  fit_resamples(remote ~ ., 
                resamples = so_folds) %>% 
  collect_metrics()
```


# Your Turn 3

Let's combine bootstrapping with decision trees.

Do **Round 1** on your handouts.

# Your Turn 4

Now, let's add the aggregating part.

Do **Round 2** on your handouts.

# Your Turn 5

Create a new model spec called `rf_spec`, which will learn an ensemble of classification trees from our training data using the **ranger** package. 

Compare the metrics of the random forest to your two single tree models (vanilla and big)- which predicts the test set better?

*Hint: you'll need https://tidymodels.github.io/parsnip/articles/articles/Models.html*

```{r}
rf_spec <-
  rand_forest() %>% 
  set_engine("ranger") %>% 
  set_mode("classification")

set.seed(100)
rf_spec %>% 
  fit_resamples(remote ~ ., 
                resamples = so_folds) %>% 
  collect_metrics()
```

# Your Turn 6

Challenge: Make 4 more random forest model specs, each using 4, 8, 12, and 19 variables at each split. Which value maximizes the area under the ROC curve?

*Hint: you'll need https://tidymodels.github.io/parsnip/reference/rand_forest.html*

```{r}
rf4_spec <- rf_spec %>% 
  set_args(mtry = 4) #<<

set.seed(100)
rf4_spec %>% 
  fit_resamples(remote ~ ., 
                resamples = so_folds) %>% 
  collect_metrics()
```

```{r}
rf8_spec <- rf_spec %>% 
  set_args(mtry = 8) #<<

set.seed(100)
rf8_spec %>% 
  fit_resamples(remote ~ ., 
                resamples = so_folds) %>% 
  collect_metrics()
```

```{r}
rf12_spec <- rf_spec %>% 
  set_args(mtry = 12) #<<

set.seed(100)
rf12_spec %>% 
  fit_resamples(remote ~ ., 
                resamples = so_folds) %>% 
  collect_metrics()
```

```{r}
rf19_spec <- rf_spec %>% 
  set_args(mtry = 19) #<<

set.seed(100)
rf19_spec %>% 
  fit_resamples(remote ~ ., 
                resamples = so_folds) %>% 
  collect_metrics()
```


# Your Turn 7

Make a new model spec called `treebag_imp_spec` to fit a bagged classification tree model. Set the variable `importance` mode to "permutation". Plot the variable importance- which variable was the most important?

```{r}
treebag_imp_spec <-
  rand_forest(mtry = .preds()) %>% 
  set_engine("ranger", importance = 'permutation') %>% 
  set_mode("classification")

treebag_wf <-
  workflow() %>% 
  add_formula(remote ~ .) %>% 
  add_model(treebag_imp_spec)

imp_fit <- 
  treebag_wf %>% 
  last_fit(split = so_split)

imp_plot <- get_tree_fit(imp_fit)

vip::vip(imp_plot, geom = "point")
```




